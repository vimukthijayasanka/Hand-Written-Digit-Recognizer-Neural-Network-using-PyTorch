{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaFdqAwQnEGl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets # Import the necessary libraries from the torchvision package\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the MNIST training dataset if it's not already present in the specified root directory.\n",
        "# Convert the images to PyTorch tensors for further processing.\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",    # Directory where the data will be stored\n",
        "    train=True,     # Specifies that this is the training set\n",
        "    download=True,  # Downloads the data if it's not already present\n",
        "    transform=ToTensor()  # Converts the images to PyTorch tensors\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,     # Specifies that this is the test set\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "34ftMzP5nuGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXeekEjxoGU2",
        "outputId": "425462b4-3c17-4b22-b623-a2aae032042b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbafRIHmoKZL",
        "outputId": "41de50a8-def8-407a-a0c0-9d0527076799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kpir5d-oLmA",
        "outputId": "f4325389-3472-482a-bf83-b9038b89fb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_dcWhTco64M",
        "outputId": "e19cf300-f752-4d61-b911-cd45c14973a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    'train':DataLoader(train_data,\n",
        "                       batch_size = 100,\n",
        "                       shuffle=True,\n",
        "                       num_workers =1),\n",
        "\n",
        "    'test':DataLoader(test_data,\n",
        "                       batch_size = 500,\n",
        "                       shuffle=False,\n",
        "                       num_workers =1),\n",
        "}"
      ],
      "metadata": {
        "id": "jucgeYuno-Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtaWHdUqrn7",
        "outputId": "17233da1-a285-48cf-bd01-02ebc7444508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7ec5607dfe20>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7ec560867a90>}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "7B795h_PqsjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.softmax(x)\n",
        "    #return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "mg08S7qbrBTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import ItemsView\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "        print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):0f}%)]\\t{loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders['test']:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output,target).item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n"
      ],
      "metadata": {
        "id": "oow67ig7sluq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk5tK7o3syav",
        "outputId": "29f8d666-92a2-480f-9e09-56e517b9cacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-da28291b5edc>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0.000000%)]\t2.302649\n",
            "Train Epoch: 1 [2000/60000 (3.333333%)]\t2.287220\n",
            "Train Epoch: 1 [4000/60000 (6.666667%)]\t2.147398\n",
            "Train Epoch: 1 [6000/60000 (10.000000%)]\t2.058741\n",
            "Train Epoch: 1 [8000/60000 (13.333333%)]\t1.877689\n",
            "Train Epoch: 1 [10000/60000 (16.666667%)]\t1.801319\n",
            "Train Epoch: 1 [12000/60000 (20.000000%)]\t1.822429\n",
            "Train Epoch: 1 [14000/60000 (23.333333%)]\t1.737651\n",
            "Train Epoch: 1 [16000/60000 (26.666667%)]\t1.694881\n",
            "Train Epoch: 1 [18000/60000 (30.000000%)]\t1.720263\n",
            "Train Epoch: 1 [20000/60000 (33.333333%)]\t1.698982\n",
            "Train Epoch: 1 [22000/60000 (36.666667%)]\t1.696465\n",
            "Train Epoch: 1 [24000/60000 (40.000000%)]\t1.735418\n",
            "Train Epoch: 1 [26000/60000 (43.333333%)]\t1.679265\n",
            "Train Epoch: 1 [28000/60000 (46.666667%)]\t1.643119\n",
            "Train Epoch: 1 [30000/60000 (50.000000%)]\t1.632842\n",
            "Train Epoch: 1 [32000/60000 (53.333333%)]\t1.605285\n",
            "Train Epoch: 1 [34000/60000 (56.666667%)]\t1.603880\n",
            "Train Epoch: 1 [36000/60000 (60.000000%)]\t1.584444\n",
            "Train Epoch: 1 [38000/60000 (63.333333%)]\t1.633136\n",
            "Train Epoch: 1 [40000/60000 (66.666667%)]\t1.662868\n",
            "Train Epoch: 1 [42000/60000 (70.000000%)]\t1.573833\n",
            "Train Epoch: 1 [44000/60000 (73.333333%)]\t1.632149\n",
            "Train Epoch: 1 [46000/60000 (76.666667%)]\t1.564703\n",
            "Train Epoch: 1 [48000/60000 (80.000000%)]\t1.565408\n",
            "Train Epoch: 1 [50000/60000 (83.333333%)]\t1.565487\n",
            "Train Epoch: 1 [52000/60000 (86.666667%)]\t1.625933\n",
            "Train Epoch: 1 [54000/60000 (90.000000%)]\t1.623027\n",
            "Train Epoch: 1 [56000/60000 (93.333333%)]\t1.655441\n",
            "Train Epoch: 1 [58000/60000 (96.666667%)]\t1.572466\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9397/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0.000000%)]\t1.649950\n",
            "Train Epoch: 2 [2000/60000 (3.333333%)]\t1.550915\n",
            "Train Epoch: 2 [4000/60000 (6.666667%)]\t1.611149\n",
            "Train Epoch: 2 [6000/60000 (10.000000%)]\t1.601972\n",
            "Train Epoch: 2 [8000/60000 (13.333333%)]\t1.562407\n",
            "Train Epoch: 2 [10000/60000 (16.666667%)]\t1.593155\n",
            "Train Epoch: 2 [12000/60000 (20.000000%)]\t1.549754\n",
            "Train Epoch: 2 [14000/60000 (23.333333%)]\t1.558845\n",
            "Train Epoch: 2 [16000/60000 (26.666667%)]\t1.628630\n",
            "Train Epoch: 2 [18000/60000 (30.000000%)]\t1.532798\n",
            "Train Epoch: 2 [20000/60000 (33.333333%)]\t1.574423\n",
            "Train Epoch: 2 [22000/60000 (36.666667%)]\t1.569261\n",
            "Train Epoch: 2 [24000/60000 (40.000000%)]\t1.582306\n",
            "Train Epoch: 2 [26000/60000 (43.333333%)]\t1.560889\n",
            "Train Epoch: 2 [28000/60000 (46.666667%)]\t1.538561\n",
            "Train Epoch: 2 [30000/60000 (50.000000%)]\t1.605853\n",
            "Train Epoch: 2 [32000/60000 (53.333333%)]\t1.613597\n",
            "Train Epoch: 2 [34000/60000 (56.666667%)]\t1.585982\n",
            "Train Epoch: 2 [36000/60000 (60.000000%)]\t1.604294\n",
            "Train Epoch: 2 [38000/60000 (63.333333%)]\t1.568137\n",
            "Train Epoch: 2 [40000/60000 (66.666667%)]\t1.608062\n",
            "Train Epoch: 2 [42000/60000 (70.000000%)]\t1.541282\n",
            "Train Epoch: 2 [44000/60000 (73.333333%)]\t1.588099\n",
            "Train Epoch: 2 [46000/60000 (76.666667%)]\t1.561979\n",
            "Train Epoch: 2 [48000/60000 (80.000000%)]\t1.539543\n",
            "Train Epoch: 2 [50000/60000 (83.333333%)]\t1.571524\n",
            "Train Epoch: 2 [52000/60000 (86.666667%)]\t1.573763\n",
            "Train Epoch: 2 [54000/60000 (90.000000%)]\t1.587316\n",
            "Train Epoch: 2 [56000/60000 (93.333333%)]\t1.548958\n",
            "Train Epoch: 2 [58000/60000 (96.666667%)]\t1.591573\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9585/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0.000000%)]\t1.578839\n",
            "Train Epoch: 3 [2000/60000 (3.333333%)]\t1.575875\n",
            "Train Epoch: 3 [4000/60000 (6.666667%)]\t1.540325\n",
            "Train Epoch: 3 [6000/60000 (10.000000%)]\t1.542939\n",
            "Train Epoch: 3 [8000/60000 (13.333333%)]\t1.552030\n",
            "Train Epoch: 3 [10000/60000 (16.666667%)]\t1.558210\n",
            "Train Epoch: 3 [12000/60000 (20.000000%)]\t1.584670\n",
            "Train Epoch: 3 [14000/60000 (23.333333%)]\t1.555498\n",
            "Train Epoch: 3 [16000/60000 (26.666667%)]\t1.533893\n",
            "Train Epoch: 3 [18000/60000 (30.000000%)]\t1.527073\n",
            "Train Epoch: 3 [20000/60000 (33.333333%)]\t1.577590\n",
            "Train Epoch: 3 [22000/60000 (36.666667%)]\t1.539606\n",
            "Train Epoch: 3 [24000/60000 (40.000000%)]\t1.571050\n",
            "Train Epoch: 3 [26000/60000 (43.333333%)]\t1.584093\n",
            "Train Epoch: 3 [28000/60000 (46.666667%)]\t1.504267\n",
            "Train Epoch: 3 [30000/60000 (50.000000%)]\t1.558671\n",
            "Train Epoch: 3 [32000/60000 (53.333333%)]\t1.516918\n",
            "Train Epoch: 3 [34000/60000 (56.666667%)]\t1.557259\n",
            "Train Epoch: 3 [36000/60000 (60.000000%)]\t1.592280\n",
            "Train Epoch: 3 [38000/60000 (63.333333%)]\t1.584093\n",
            "Train Epoch: 3 [40000/60000 (66.666667%)]\t1.532422\n",
            "Train Epoch: 3 [42000/60000 (70.000000%)]\t1.539411\n",
            "Train Epoch: 3 [44000/60000 (73.333333%)]\t1.532105\n",
            "Train Epoch: 3 [46000/60000 (76.666667%)]\t1.532548\n",
            "Train Epoch: 3 [48000/60000 (80.000000%)]\t1.513414\n",
            "Train Epoch: 3 [50000/60000 (83.333333%)]\t1.533092\n",
            "Train Epoch: 3 [52000/60000 (86.666667%)]\t1.549496\n",
            "Train Epoch: 3 [54000/60000 (90.000000%)]\t1.554317\n",
            "Train Epoch: 3 [56000/60000 (93.333333%)]\t1.572832\n",
            "Train Epoch: 3 [58000/60000 (96.666667%)]\t1.501977\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9647/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0.000000%)]\t1.511602\n",
            "Train Epoch: 4 [2000/60000 (3.333333%)]\t1.517057\n",
            "Train Epoch: 4 [4000/60000 (6.666667%)]\t1.554551\n",
            "Train Epoch: 4 [6000/60000 (10.000000%)]\t1.561593\n",
            "Train Epoch: 4 [8000/60000 (13.333333%)]\t1.560476\n",
            "Train Epoch: 4 [10000/60000 (16.666667%)]\t1.571013\n",
            "Train Epoch: 4 [12000/60000 (20.000000%)]\t1.578881\n",
            "Train Epoch: 4 [14000/60000 (23.333333%)]\t1.556967\n",
            "Train Epoch: 4 [16000/60000 (26.666667%)]\t1.523066\n",
            "Train Epoch: 4 [18000/60000 (30.000000%)]\t1.527549\n",
            "Train Epoch: 4 [20000/60000 (33.333333%)]\t1.563457\n",
            "Train Epoch: 4 [22000/60000 (36.666667%)]\t1.534095\n",
            "Train Epoch: 4 [24000/60000 (40.000000%)]\t1.542804\n",
            "Train Epoch: 4 [26000/60000 (43.333333%)]\t1.541849\n",
            "Train Epoch: 4 [28000/60000 (46.666667%)]\t1.536065\n",
            "Train Epoch: 4 [30000/60000 (50.000000%)]\t1.496890\n",
            "Train Epoch: 4 [32000/60000 (53.333333%)]\t1.502455\n",
            "Train Epoch: 4 [34000/60000 (56.666667%)]\t1.522722\n",
            "Train Epoch: 4 [36000/60000 (60.000000%)]\t1.508599\n",
            "Train Epoch: 4 [38000/60000 (63.333333%)]\t1.551385\n",
            "Train Epoch: 4 [40000/60000 (66.666667%)]\t1.590130\n",
            "Train Epoch: 4 [42000/60000 (70.000000%)]\t1.599964\n",
            "Train Epoch: 4 [44000/60000 (73.333333%)]\t1.541815\n",
            "Train Epoch: 4 [46000/60000 (76.666667%)]\t1.523959\n",
            "Train Epoch: 4 [48000/60000 (80.000000%)]\t1.549713\n",
            "Train Epoch: 4 [50000/60000 (83.333333%)]\t1.524545\n",
            "Train Epoch: 4 [52000/60000 (86.666667%)]\t1.567219\n",
            "Train Epoch: 4 [54000/60000 (90.000000%)]\t1.574085\n",
            "Train Epoch: 4 [56000/60000 (93.333333%)]\t1.508962\n",
            "Train Epoch: 4 [58000/60000 (96.666667%)]\t1.582076\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0.000000%)]\t1.544898\n",
            "Train Epoch: 5 [2000/60000 (3.333333%)]\t1.523042\n",
            "Train Epoch: 5 [4000/60000 (6.666667%)]\t1.528203\n",
            "Train Epoch: 5 [6000/60000 (10.000000%)]\t1.537688\n",
            "Train Epoch: 5 [8000/60000 (13.333333%)]\t1.506362\n",
            "Train Epoch: 5 [10000/60000 (16.666667%)]\t1.544403\n",
            "Train Epoch: 5 [12000/60000 (20.000000%)]\t1.500900\n",
            "Train Epoch: 5 [14000/60000 (23.333333%)]\t1.530335\n",
            "Train Epoch: 5 [16000/60000 (26.666667%)]\t1.587561\n",
            "Train Epoch: 5 [18000/60000 (30.000000%)]\t1.577180\n",
            "Train Epoch: 5 [20000/60000 (33.333333%)]\t1.523848\n",
            "Train Epoch: 5 [22000/60000 (36.666667%)]\t1.513241\n",
            "Train Epoch: 5 [24000/60000 (40.000000%)]\t1.526597\n",
            "Train Epoch: 5 [26000/60000 (43.333333%)]\t1.536211\n",
            "Train Epoch: 5 [28000/60000 (46.666667%)]\t1.532898\n",
            "Train Epoch: 5 [30000/60000 (50.000000%)]\t1.575534\n",
            "Train Epoch: 5 [32000/60000 (53.333333%)]\t1.535259\n",
            "Train Epoch: 5 [34000/60000 (56.666667%)]\t1.542398\n",
            "Train Epoch: 5 [36000/60000 (60.000000%)]\t1.524903\n",
            "Train Epoch: 5 [38000/60000 (63.333333%)]\t1.481979\n",
            "Train Epoch: 5 [40000/60000 (66.666667%)]\t1.563581\n",
            "Train Epoch: 5 [42000/60000 (70.000000%)]\t1.509669\n",
            "Train Epoch: 5 [44000/60000 (73.333333%)]\t1.555221\n",
            "Train Epoch: 5 [46000/60000 (76.666667%)]\t1.532974\n",
            "Train Epoch: 5 [48000/60000 (80.000000%)]\t1.524880\n",
            "Train Epoch: 5 [50000/60000 (83.333333%)]\t1.510906\n",
            "Train Epoch: 5 [52000/60000 (86.666667%)]\t1.586195\n",
            "Train Epoch: 5 [54000/60000 (90.000000%)]\t1.557963\n",
            "Train Epoch: 5 [56000/60000 (93.333333%)]\t1.544103\n",
            "Train Epoch: 5 [58000/60000 (96.666667%)]\t1.533503\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0.000000%)]\t1.493047\n",
            "Train Epoch: 6 [2000/60000 (3.333333%)]\t1.525725\n",
            "Train Epoch: 6 [4000/60000 (6.666667%)]\t1.572243\n",
            "Train Epoch: 6 [6000/60000 (10.000000%)]\t1.545842\n",
            "Train Epoch: 6 [8000/60000 (13.333333%)]\t1.508849\n",
            "Train Epoch: 6 [10000/60000 (16.666667%)]\t1.544119\n",
            "Train Epoch: 6 [12000/60000 (20.000000%)]\t1.512995\n",
            "Train Epoch: 6 [14000/60000 (23.333333%)]\t1.522623\n",
            "Train Epoch: 6 [16000/60000 (26.666667%)]\t1.562827\n",
            "Train Epoch: 6 [18000/60000 (30.000000%)]\t1.535961\n",
            "Train Epoch: 6 [20000/60000 (33.333333%)]\t1.558143\n",
            "Train Epoch: 6 [22000/60000 (36.666667%)]\t1.519798\n",
            "Train Epoch: 6 [24000/60000 (40.000000%)]\t1.495791\n",
            "Train Epoch: 6 [26000/60000 (43.333333%)]\t1.507641\n",
            "Train Epoch: 6 [28000/60000 (46.666667%)]\t1.551035\n",
            "Train Epoch: 6 [30000/60000 (50.000000%)]\t1.541862\n",
            "Train Epoch: 6 [32000/60000 (53.333333%)]\t1.499271\n",
            "Train Epoch: 6 [34000/60000 (56.666667%)]\t1.566405\n",
            "Train Epoch: 6 [36000/60000 (60.000000%)]\t1.572566\n",
            "Train Epoch: 6 [38000/60000 (63.333333%)]\t1.479291\n",
            "Train Epoch: 6 [40000/60000 (66.666667%)]\t1.534476\n",
            "Train Epoch: 6 [42000/60000 (70.000000%)]\t1.497746\n",
            "Train Epoch: 6 [44000/60000 (73.333333%)]\t1.572740\n",
            "Train Epoch: 6 [46000/60000 (76.666667%)]\t1.544244\n",
            "Train Epoch: 6 [48000/60000 (80.000000%)]\t1.530329\n",
            "Train Epoch: 6 [50000/60000 (83.333333%)]\t1.529925\n",
            "Train Epoch: 6 [52000/60000 (86.666667%)]\t1.512218\n",
            "Train Epoch: 6 [54000/60000 (90.000000%)]\t1.477322\n",
            "Train Epoch: 6 [56000/60000 (93.333333%)]\t1.512011\n",
            "Train Epoch: 6 [58000/60000 (96.666667%)]\t1.513751\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9725/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0.000000%)]\t1.543157\n",
            "Train Epoch: 7 [2000/60000 (3.333333%)]\t1.520124\n",
            "Train Epoch: 7 [4000/60000 (6.666667%)]\t1.540537\n",
            "Train Epoch: 7 [6000/60000 (10.000000%)]\t1.499195\n",
            "Train Epoch: 7 [8000/60000 (13.333333%)]\t1.542569\n",
            "Train Epoch: 7 [10000/60000 (16.666667%)]\t1.515083\n",
            "Train Epoch: 7 [12000/60000 (20.000000%)]\t1.511463\n",
            "Train Epoch: 7 [14000/60000 (23.333333%)]\t1.540804\n",
            "Train Epoch: 7 [16000/60000 (26.666667%)]\t1.531232\n",
            "Train Epoch: 7 [18000/60000 (30.000000%)]\t1.527869\n",
            "Train Epoch: 7 [20000/60000 (33.333333%)]\t1.510904\n",
            "Train Epoch: 7 [22000/60000 (36.666667%)]\t1.526833\n",
            "Train Epoch: 7 [24000/60000 (40.000000%)]\t1.502059\n",
            "Train Epoch: 7 [26000/60000 (43.333333%)]\t1.523999\n",
            "Train Epoch: 7 [28000/60000 (46.666667%)]\t1.545348\n",
            "Train Epoch: 7 [30000/60000 (50.000000%)]\t1.521469\n",
            "Train Epoch: 7 [32000/60000 (53.333333%)]\t1.510724\n",
            "Train Epoch: 7 [34000/60000 (56.666667%)]\t1.535885\n",
            "Train Epoch: 7 [36000/60000 (60.000000%)]\t1.543516\n",
            "Train Epoch: 7 [38000/60000 (63.333333%)]\t1.508617\n",
            "Train Epoch: 7 [40000/60000 (66.666667%)]\t1.546510\n",
            "Train Epoch: 7 [42000/60000 (70.000000%)]\t1.530326\n",
            "Train Epoch: 7 [44000/60000 (73.333333%)]\t1.519650\n",
            "Train Epoch: 7 [46000/60000 (76.666667%)]\t1.519971\n",
            "Train Epoch: 7 [48000/60000 (80.000000%)]\t1.542830\n",
            "Train Epoch: 7 [50000/60000 (83.333333%)]\t1.533395\n",
            "Train Epoch: 7 [52000/60000 (86.666667%)]\t1.491454\n",
            "Train Epoch: 7 [54000/60000 (90.000000%)]\t1.517748\n",
            "Train Epoch: 7 [56000/60000 (93.333333%)]\t1.492974\n",
            "Train Epoch: 7 [58000/60000 (96.666667%)]\t1.518411\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9768/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0.000000%)]\t1.543471\n",
            "Train Epoch: 8 [2000/60000 (3.333333%)]\t1.538175\n",
            "Train Epoch: 8 [4000/60000 (6.666667%)]\t1.504870\n",
            "Train Epoch: 8 [6000/60000 (10.000000%)]\t1.547444\n",
            "Train Epoch: 8 [8000/60000 (13.333333%)]\t1.526628\n",
            "Train Epoch: 8 [10000/60000 (16.666667%)]\t1.501672\n",
            "Train Epoch: 8 [12000/60000 (20.000000%)]\t1.557056\n",
            "Train Epoch: 8 [14000/60000 (23.333333%)]\t1.516485\n",
            "Train Epoch: 8 [16000/60000 (26.666667%)]\t1.528829\n",
            "Train Epoch: 8 [18000/60000 (30.000000%)]\t1.519602\n",
            "Train Epoch: 8 [20000/60000 (33.333333%)]\t1.530020\n",
            "Train Epoch: 8 [22000/60000 (36.666667%)]\t1.522720\n",
            "Train Epoch: 8 [24000/60000 (40.000000%)]\t1.561390\n",
            "Train Epoch: 8 [26000/60000 (43.333333%)]\t1.524962\n",
            "Train Epoch: 8 [28000/60000 (46.666667%)]\t1.531601\n",
            "Train Epoch: 8 [30000/60000 (50.000000%)]\t1.488613\n",
            "Train Epoch: 8 [32000/60000 (53.333333%)]\t1.524252\n",
            "Train Epoch: 8 [34000/60000 (56.666667%)]\t1.493582\n",
            "Train Epoch: 8 [36000/60000 (60.000000%)]\t1.549633\n",
            "Train Epoch: 8 [38000/60000 (63.333333%)]\t1.514530\n",
            "Train Epoch: 8 [40000/60000 (66.666667%)]\t1.512873\n",
            "Train Epoch: 8 [42000/60000 (70.000000%)]\t1.558356\n",
            "Train Epoch: 8 [44000/60000 (73.333333%)]\t1.512158\n",
            "Train Epoch: 8 [46000/60000 (76.666667%)]\t1.509265\n",
            "Train Epoch: 8 [48000/60000 (80.000000%)]\t1.551854\n",
            "Train Epoch: 8 [50000/60000 (83.333333%)]\t1.521348\n",
            "Train Epoch: 8 [52000/60000 (86.666667%)]\t1.532881\n",
            "Train Epoch: 8 [54000/60000 (90.000000%)]\t1.534866\n",
            "Train Epoch: 8 [56000/60000 (93.333333%)]\t1.536414\n",
            "Train Epoch: 8 [58000/60000 (96.666667%)]\t1.507440\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9768/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0.000000%)]\t1.512886\n",
            "Train Epoch: 9 [2000/60000 (3.333333%)]\t1.520383\n",
            "Train Epoch: 9 [4000/60000 (6.666667%)]\t1.561240\n",
            "Train Epoch: 9 [6000/60000 (10.000000%)]\t1.528257\n",
            "Train Epoch: 9 [8000/60000 (13.333333%)]\t1.503236\n",
            "Train Epoch: 9 [10000/60000 (16.666667%)]\t1.527586\n",
            "Train Epoch: 9 [12000/60000 (20.000000%)]\t1.472370\n",
            "Train Epoch: 9 [14000/60000 (23.333333%)]\t1.497459\n",
            "Train Epoch: 9 [16000/60000 (26.666667%)]\t1.554437\n",
            "Train Epoch: 9 [18000/60000 (30.000000%)]\t1.522997\n",
            "Train Epoch: 9 [20000/60000 (33.333333%)]\t1.500116\n",
            "Train Epoch: 9 [22000/60000 (36.666667%)]\t1.511891\n",
            "Train Epoch: 9 [24000/60000 (40.000000%)]\t1.502560\n",
            "Train Epoch: 9 [26000/60000 (43.333333%)]\t1.531332\n",
            "Train Epoch: 9 [28000/60000 (46.666667%)]\t1.514675\n",
            "Train Epoch: 9 [30000/60000 (50.000000%)]\t1.506942\n",
            "Train Epoch: 9 [32000/60000 (53.333333%)]\t1.506609\n",
            "Train Epoch: 9 [34000/60000 (56.666667%)]\t1.559422\n",
            "Train Epoch: 9 [36000/60000 (60.000000%)]\t1.550116\n",
            "Train Epoch: 9 [38000/60000 (63.333333%)]\t1.561934\n",
            "Train Epoch: 9 [40000/60000 (66.666667%)]\t1.524263\n",
            "Train Epoch: 9 [42000/60000 (70.000000%)]\t1.536402\n",
            "Train Epoch: 9 [44000/60000 (73.333333%)]\t1.508326\n",
            "Train Epoch: 9 [46000/60000 (76.666667%)]\t1.561400\n",
            "Train Epoch: 9 [48000/60000 (80.000000%)]\t1.550321\n",
            "Train Epoch: 9 [50000/60000 (83.333333%)]\t1.525459\n",
            "Train Epoch: 9 [52000/60000 (86.666667%)]\t1.507817\n",
            "Train Epoch: 9 [54000/60000 (90.000000%)]\t1.507025\n",
            "Train Epoch: 9 [56000/60000 (93.333333%)]\t1.520130\n",
            "Train Epoch: 9 [58000/60000 (96.666667%)]\t1.491845\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9787/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0.000000%)]\t1.494424\n",
            "Train Epoch: 10 [2000/60000 (3.333333%)]\t1.521590\n",
            "Train Epoch: 10 [4000/60000 (6.666667%)]\t1.534052\n",
            "Train Epoch: 10 [6000/60000 (10.000000%)]\t1.494596\n",
            "Train Epoch: 10 [8000/60000 (13.333333%)]\t1.532648\n",
            "Train Epoch: 10 [10000/60000 (16.666667%)]\t1.536273\n",
            "Train Epoch: 10 [12000/60000 (20.000000%)]\t1.552926\n",
            "Train Epoch: 10 [14000/60000 (23.333333%)]\t1.528302\n",
            "Train Epoch: 10 [16000/60000 (26.666667%)]\t1.498021\n",
            "Train Epoch: 10 [18000/60000 (30.000000%)]\t1.501614\n",
            "Train Epoch: 10 [20000/60000 (33.333333%)]\t1.493243\n",
            "Train Epoch: 10 [22000/60000 (36.666667%)]\t1.487377\n",
            "Train Epoch: 10 [24000/60000 (40.000000%)]\t1.567049\n",
            "Train Epoch: 10 [26000/60000 (43.333333%)]\t1.496514\n",
            "Train Epoch: 10 [28000/60000 (46.666667%)]\t1.490036\n",
            "Train Epoch: 10 [30000/60000 (50.000000%)]\t1.529592\n",
            "Train Epoch: 10 [32000/60000 (53.333333%)]\t1.497977\n",
            "Train Epoch: 10 [34000/60000 (56.666667%)]\t1.489699\n",
            "Train Epoch: 10 [36000/60000 (60.000000%)]\t1.526753\n",
            "Train Epoch: 10 [38000/60000 (63.333333%)]\t1.548752\n",
            "Train Epoch: 10 [40000/60000 (66.666667%)]\t1.494865\n",
            "Train Epoch: 10 [42000/60000 (70.000000%)]\t1.538041\n",
            "Train Epoch: 10 [44000/60000 (73.333333%)]\t1.509540\n",
            "Train Epoch: 10 [46000/60000 (76.666667%)]\t1.520482\n",
            "Train Epoch: 10 [48000/60000 (80.000000%)]\t1.527280\n",
            "Train Epoch: 10 [50000/60000 (83.333333%)]\t1.541404\n",
            "Train Epoch: 10 [52000/60000 (86.666667%)]\t1.542480\n",
            "Train Epoch: 10 [54000/60000 (90.000000%)]\t1.494644\n",
            "Train Epoch: 10 [56000/60000 (93.333333%)]\t1.480230\n",
            "Train Epoch: 10 [58000/60000 (96.666667%)]\t1.485660\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9779/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKMD49lW2fp7",
        "outputId": "00f3495b-83fc-4f11-f53c-0d0a5c1005eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "data, target = test_data[500]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "FUrbdZ_X2_Lj",
        "outputId": "5211b6d6-c1c1-4f3f-eeb5-bd0f4f9f283f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-da28291b5edc>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}